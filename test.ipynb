{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys  # Importing Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# Other imports\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email: neil.treat@gmail.com\n",
      "Password: *************\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Verify that credentials are loaded\n",
    "print(f\"Email: {email}\")\n",
    "print(f\"Password: {'*' * len(password) if password else 'Not Found'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 elements with selector //a[text()='Show all']\n",
      "Element 1:\n",
      "  Text: Show all\n",
      "  Is displayed: True\n",
      "  Location: {'x': 1124, 'y': 2576}\n",
      "  HTML: <a href=\"#\" class=\"underline\">Show all</a>\n",
      "\n",
      "UTR Statistics:\n",
      "--------------------------------------------------\n",
      "Latest Rating: 16.21\n",
      "Highest Rating: 16.35\n",
      "Lowest Rating: 11.06\n",
      "Average Rating: 14.86\n",
      "Total Records: 435\n",
      "Date Range: 2016-06-27 to 2024-11-11\n",
      "\n",
      "Data saved to utr_history.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='scraper.log', level=logging.INFO,\n",
    "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    \n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "def perform_login(driver, wait):\n",
    "    driver.get(\"https://app.utrsports.net/login\")\n",
    "    logging.info(\"Navigated to login page\")\n",
    "    \n",
    "    # Wait for email field and enter credentials\n",
    "    email_field = wait.until(EC.presence_of_element_located((By.ID, \"emailInput\")))\n",
    "    email_field.clear()\n",
    "    email_field.send_keys(email)\n",
    "    \n",
    "    password_field = driver.find_element(By.ID, \"passwordInput\")\n",
    "    password_field.clear()\n",
    "    password_field.send_keys(password)\n",
    "    \n",
    "    # Click sign in\n",
    "    sign_in_button = wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='SIGN IN']\"))\n",
    "    )\n",
    "    sign_in_button.click()\n",
    "    logging.info(\"Clicked sign in button\")\n",
    "    \n",
    "    # Wait for and click continue button\n",
    "    continue_button = wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//button[text()='Continue']\"))\n",
    "    )\n",
    "    continue_button.click()\n",
    "    logging.info(\"Login completed successfully\")\n",
    "\n",
    "def navigate_to_stats(driver, wait, stats_url):\n",
    "    driver.get(stats_url)\n",
    "    logging.info(f\"Navigated to stats page: {stats_url}\")\n",
    "    # Wait for page load\n",
    "    time.sleep(5)\n",
    "\n",
    "def find_show_all_link(driver, wait):\n",
    "    \"\"\"Try multiple strategies to find the 'Show all' link\"\"\"\n",
    "    # List of possible XPath and CSS selectors to try\n",
    "    selectors = [\n",
    "        (By.XPATH, \"//a[text()='Show all']\"),\n",
    "        (By.XPATH, \"//a[contains(text(), 'Show all')]\"),\n",
    "        (By.XPATH, \"//div[contains(@class, 'mt32')]//a[text()='Show all']\"),\n",
    "        (By.CSS_SELECTOR, \"a[href*='show-all']\"),  # If the link contains 'show-all' in href\n",
    "        (By.LINK_TEXT, \"Show all\"),\n",
    "        (By.PARTIAL_LINK_TEXT, \"Show all\")\n",
    "    ]\n",
    "    \n",
    "    # Try each selector\n",
    "    for by, selector in selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(by, selector)\n",
    "            if elements:\n",
    "                # Print information about found elements\n",
    "                print(f\"Found {len(elements)} elements with selector {selector}\")\n",
    "                for idx, elem in enumerate(elements):\n",
    "                    try:\n",
    "                        print(f\"Element {idx + 1}:\")\n",
    "                        print(f\"  Text: {elem.text}\")\n",
    "                        print(f\"  Is displayed: {elem.is_displayed()}\")\n",
    "                        print(f\"  Location: {elem.location}\")\n",
    "                        print(f\"  HTML: {elem.get_attribute('outerHTML')}\")\n",
    "                    except:\n",
    "                        continue\n",
    "                return elements\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    return []\n",
    "\n",
    "def click_show_all(driver, wait):\n",
    "    # Scroll to bottom to ensure all content is loaded\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Find the Show all link\n",
    "    show_all_elements = find_show_all_link(driver, wait)\n",
    "    \n",
    "    if not show_all_elements:\n",
    "        # If no elements found, take a screenshot and log the page source\n",
    "        driver.save_screenshot(\"no_show_all_found.png\")\n",
    "        with open(\"page_source.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(driver.page_source)\n",
    "        raise Exception(\"No 'Show all' link found. Screenshot and page source saved.\")\n",
    "    \n",
    "    # Try to click the last \"Show all\" link\n",
    "    show_all_link = show_all_elements[-1]\n",
    "    \n",
    "    # Try multiple click methods\n",
    "    click_methods = [\n",
    "        lambda: show_all_link.click(),  # Regular click\n",
    "        lambda: ActionChains(driver).move_to_element(show_all_link).click().perform(),  # Action chains click\n",
    "        lambda: driver.execute_script(\"arguments[0].click();\", show_all_link)  # JavaScript click\n",
    "    ]\n",
    "    \n",
    "    for click_method in click_methods:\n",
    "        try:\n",
    "            # Scroll the element into view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", show_all_link)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Try to click\n",
    "            click_method()\n",
    "            logging.info(\"Successfully clicked 'Show all' link\")\n",
    "            time.sleep(3)  # Wait for content to load\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Click method failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    raise Exception(\"Failed to click 'Show all' link with all methods\")\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_utr_data(html_content):\n",
    "    # Create BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Find all history items\n",
    "    history_items = soup.find_all('div', class_='newStatsTabContent__historyItem__1Nb0C')\n",
    "    \n",
    "    # Lists to store data\n",
    "    dates = []\n",
    "    ratings = []\n",
    "    \n",
    "    # Extract data from each history item\n",
    "    for item in history_items:\n",
    "        # Extract date\n",
    "        date = item.find('div', class_='newStatsTabContent__historyItemDate__jFJyD').text.strip()\n",
    "        \n",
    "        # Extract rating\n",
    "        rating = item.find('div', class_='newStatsTabContent__historyItemRating__GQUXw').text.strip()\n",
    "        \n",
    "        # Append to lists\n",
    "        dates.append(date)\n",
    "        ratings.append(float(rating))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Date': pd.to_datetime(dates),\n",
    "        'UTR_Rating': ratings\n",
    "    })\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values('Date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    driver = None\n",
    "    try:\n",
    "        driver = setup_driver()\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        stats_url = \"https://app.utrsports.net/profiles/247320?t=6\"\n",
    "        \n",
    "        perform_login(driver, wait)\n",
    "        navigate_to_stats(driver, wait, stats_url)\n",
    "        \n",
    "        # Take a screenshot before attempting to click Show all\n",
    "        driver.save_screenshot(\"before_show_all.png\")\n",
    "        \n",
    "        # Get the initial page source to check if we need to click \"Show all\"\n",
    "        initial_html = driver.page_source\n",
    "        initial_soup = BeautifulSoup(initial_html, 'html.parser')\n",
    "        show_all_link = initial_soup.find('a', string='Show all')\n",
    "        \n",
    "        if show_all_link:\n",
    "            click_show_all(driver, wait)\n",
    "            # Wait for new content to load\n",
    "            time.sleep(3)\n",
    "        \n",
    "        # Get the final page source after clicking \"Show all\" (if needed)\n",
    "        html_content = driver.page_source\n",
    "        \n",
    "        # Create the DataFrame\n",
    "        df = extract_utr_data(html_content)\n",
    "\n",
    "        # Basic statistics\n",
    "        stats = {\n",
    "            'Latest Rating': df['UTR_Rating'].iloc[-1],\n",
    "            'Highest Rating': df['UTR_Rating'].max(),\n",
    "            'Lowest Rating': df['UTR_Rating'].min(),\n",
    "            'Average Rating': df['UTR_Rating'].mean(),\n",
    "            'Total Records': len(df),\n",
    "            'Date Range': f\"{df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\"\n",
    "        }\n",
    "\n",
    "        # Print some basic statistics\n",
    "        print(\"\\nUTR Statistics:\")\n",
    "        print(\"-\" * 50)\n",
    "        for key, value in stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{key}: {value:.2f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "        # Save to CSV\n",
    "        output_file = 'utr_history.csv'\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nData saved to {output_file}\")\n",
    "        \n",
    "        # Save raw HTML for debugging if needed\n",
    "        with open(\"raw_data.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        if driver:\n",
    "            driver.save_screenshot(f\"error_{int(time.time())}.png\")\n",
    "            # Save the page source when error occurs\n",
    "            with open(f\"error_page_{int(time.time())}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(driver.page_source)\n",
    "        raise e\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now need to integrate player search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigated to the login page.\n",
      "Entered email.\n",
      "Entered password.\n",
      "Clicked the 'SIGN IN' button.\n",
      "Clicked the 'Continue' button.\n",
      "Navigated to player's stats page: https://app.utrsports.net/search?sportTypes=tennis&startDate=11/21/2024&utrMin=1&utrMax=16&utrType=verified&utrTeamType=singles&utrFitPosition=6&type=players&lat=37.2358078&lng=-121.9623751\n",
      "Scraping page 1.\n",
      "Found 40 player cards on the current page.\n",
      "Scraped player 1: {'Player Name': 'Jannik Sinner', 'Location': 'M • Italy', 'Singles UTR': '16.25', 'Doubles UTR': '15.26', 'Profile Link': 'https://app.utrsports.net/profiles/247320'}\n",
      "Scraped player 2: {'Player Name': 'Carlos Alcaraz', 'Location': 'M • Spain', 'Singles UTR': '16.21', 'Doubles UTR': '14.91', 'Profile Link': 'https://app.utrsports.net/profiles/3569175'}\n",
      "UTR not found for player 3: list index out of range\n",
      "Scraped player 3: {'Player Name': 'Novak Djokovic', 'Location': 'M • Serbia', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/3568338'}\n",
      "Scraped player 4: {'Player Name': 'Alexander Zverev', 'Location': 'M • Monaco-Ville, Monaco', 'Singles UTR': '16.05', 'Doubles UTR': '14.84', 'Profile Link': 'https://app.utrsports.net/profiles/52294'}\n",
      "Scraped player 5: {'Player Name': 'Taylor Fritz', 'Location': 'M • San Diego, CA', 'Singles UTR': '15.95', 'Doubles UTR': '15.07', 'Profile Link': 'https://app.utrsports.net/profiles/60157'}\n",
      "Scraped player 6: {'Player Name': 'Ugo Humbert', 'Location': 'M • France', 'Singles UTR': '15.89', 'Doubles UTR': '14.43', 'Profile Link': 'https://app.utrsports.net/profiles/77968'}\n",
      "Scraped player 7: {'Player Name': 'Alex De Minaur', 'Location': 'M • Australia', 'Singles UTR': '15.86', 'Doubles UTR': '14.33', 'Profile Link': 'https://app.utrsports.net/profiles/4315334'}\n",
      "Scraped player 8: {'Player Name': 'Tommy Paul', 'Location': 'M • United States', 'Singles UTR': '15.84', 'Doubles UTR': '14.87', 'Profile Link': 'https://app.utrsports.net/profiles/50772'}\n",
      "Scraped player 9: {'Player Name': 'Jack Draper', 'Location': 'M • London, United Kingdom', 'Singles UTR': '15.83', 'Doubles UTR': '15.29', 'Profile Link': 'https://app.utrsports.net/profiles/439496'}\n",
      "Scraped player 10: {'Player Name': 'Daniil Medvedev', 'Location': 'M • Russia', 'Singles UTR': '15.82', 'Doubles UTR': '14.72', 'Profile Link': 'https://app.utrsports.net/profiles/3554581'}\n",
      "No UTR values found for player 11.\n",
      "Scraped player 11: {'Player Name': 'Jenson Brooksby', 'Location': 'M • Carmichael, CA', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/2631909'}\n",
      "Scraped player 12: {'Player Name': 'Tomas Machac', 'Location': 'M', 'Singles UTR': '15.74', 'Doubles UTR': '14.89', 'Profile Link': 'https://app.utrsports.net/profiles/182561'}\n",
      "Scraped player 13: {'Player Name': 'Hubert Hurkacz', 'Location': 'M • Poland', 'Singles UTR': '15.74', 'Doubles UTR': '14.24', 'Profile Link': 'https://app.utrsports.net/profiles/73237'}\n",
      "Scraped player 14: {'Player Name': 'Ben Shelton', 'Location': 'M • Gainesville, FL', 'Singles UTR': '15.73', 'Doubles UTR': '14.62', 'Profile Link': 'https://app.utrsports.net/profiles/4681258'}\n",
      "Scraped player 15: {'Player Name': 'Andrey Rublev', 'Location': 'M • Moscow, Russia', 'Singles UTR': '15.72', 'Doubles UTR': '14.81', 'Profile Link': 'https://app.utrsports.net/profiles/53840'}\n",
      "Scraped player 16: {'Player Name': 'Alexei Popyrin', 'Location': 'M • Australia', 'Singles UTR': '15.72', 'Doubles UTR': '14.33', 'Profile Link': 'https://app.utrsports.net/profiles/95506'}\n",
      "UTR not found for player 17: list index out of range\n",
      "Scraped player 17: {'Player Name': 'Matteo Berrettini', 'Location': 'M • Rome, Italy', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/52886'}\n",
      "Scraped player 18: {'Player Name': 'Felix Auger-Aliassime', 'Location': 'M • Monaco', 'Singles UTR': '15.71', 'Doubles UTR': '14.81', 'Profile Link': 'https://app.utrsports.net/profiles/2630333'}\n",
      "UTR not found for player 19: list index out of range\n",
      "Scraped player 19: {'Player Name': 'Grigor Dimitrov', 'Location': 'M • Monaco-Ville, Monaco', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/3469'}\n",
      "Scraped player 20: {'Player Name': 'Sebastian Korda', 'Location': 'M • Bradenton, FL', 'Singles UTR': '15.66', 'Doubles UTR': '14.95', 'Profile Link': 'https://app.utrsports.net/profiles/96338'}\n",
      "Scraped player 21: {'Player Name': 'Brandon Nakashima', 'Location': 'M', 'Singles UTR': '15.66', 'Doubles UTR': '14.09', 'Profile Link': 'https://app.utrsports.net/profiles/405461'}\n",
      "Scraped player 22: {'Player Name': 'Denis Shapovalov', 'Location': 'M • Nassau, The Bahamas', 'Singles UTR': '15.65', 'Doubles UTR': '15.01', 'Profile Link': 'https://app.utrsports.net/profiles/83218'}\n",
      "Scraped player 23: {'Player Name': 'Jan-Lennard Struff', 'Location': 'M • Warstein, Germany', 'Singles UTR': '15.65', 'Doubles UTR': '15.01', 'Profile Link': 'https://app.utrsports.net/profiles/207438'}\n",
      "UTR not found for player 24: list index out of range\n",
      "Scraped player 24: {'Player Name': 'Frances Tiafoe', 'Location': 'M • Orlando, FL', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/224678'}\n",
      "Scraped player 25: {'Player Name': 'Alex Michelsen', 'Location': 'M • Aliso Viejo, CA', 'Singles UTR': '15.64', 'Doubles UTR': '14.64', 'Profile Link': 'https://app.utrsports.net/profiles/168170'}\n",
      "UTR not found for player 26: list index out of range\n",
      "Scraped player 26: {'Player Name': 'Holger Vitus Nødskov Rune', 'Location': 'M • Charlottenlund, Denmark', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/2004640'}\n",
      "UTR not found for player 27: list index out of range\n",
      "Scraped player 27: {'Player Name': 'Marcos Giron', 'Location': 'M • Redondo Beach, CA', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/3875691'}\n",
      "Scraped player 28: {'Player Name': 'Lorenzo Musetti', 'Location': 'M • Italy', 'Singles UTR': '15.61', 'Doubles UTR': '14.73', 'Profile Link': 'https://app.utrsports.net/profiles/1394186'}\n",
      "Scraped player 29: {'Player Name': 'Casper Ruud', 'Location': 'M • Norway', 'Singles UTR': '15.59', 'Doubles UTR': '14.56', 'Profile Link': 'https://app.utrsports.net/profiles/95161'}\n",
      "UTR not found for player 30: list index out of range\n",
      "Scraped player 30: {'Player Name': 'Milos Raonic', 'Location': 'M • Monaco-Ville, Monaco', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/3832'}\n",
      "Scraped player 31: {'Player Name': 'Stefanos Tsitsipas', 'Location': 'M • Athens, Greece', 'Singles UTR': '15.56', 'Doubles UTR': '14.15', 'Profile Link': 'https://app.utrsports.net/profiles/94283'}\n",
      "UTR not found for player 32: list index out of range\n",
      "Scraped player 32: {'Player Name': 'Jiri Lehecka', 'Location': 'M • Czechia', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/273063'}\n",
      "UTR not found for player 33: list index out of range\n",
      "Scraped player 33: {'Player Name': 'Thanasi Kokkinakis', 'Location': 'M • Adelaide, Australia', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/28081'}\n",
      "Scraped player 34: {'Player Name': 'Karen Khachanov', 'Location': 'M • Dubai, United Arab Emirates', 'Singles UTR': '15.55', 'Doubles UTR': '14.96', 'Profile Link': 'https://app.utrsports.net/profiles/54351'}\n",
      "Scraped player 35: {'Player Name': 'Arthur Fils', 'Location': 'M • France', 'Singles UTR': '15.54', 'Doubles UTR': '14.85', 'Profile Link': 'https://app.utrsports.net/profiles/281770'}\n",
      "Scraped player 36: {'Player Name': 'Jordan Thompson', 'Location': 'M • Bradenton, FL', 'Singles UTR': '15.52', 'Doubles UTR': '14.99', 'Profile Link': 'https://app.utrsports.net/profiles/2611704'}\n",
      "Scraped player 37: {'Player Name': 'Rafael Nadal', 'Location': 'M • Spain', 'Singles UTR': '15.51', 'Doubles UTR': '14.91', 'Profile Link': 'https://app.utrsports.net/profiles/3109578'}\n",
      "Scraped player 38: {'Player Name': 'Tomas Martin Etcheverry', 'Location': 'M • Argentina', 'Singles UTR': '15.48', 'Doubles UTR': '14.49', 'Profile Link': 'https://app.utrsports.net/profiles/191111'}\n",
      "UTR not found for player 39: list index out of range\n",
      "Scraped player 39: {'Player Name': 'David Goffin', 'Location': 'M • Monaco-Ville, Monaco', 'Singles UTR': 'N/A', 'Doubles UTR': 'N/A', 'Profile Link': 'https://app.utrsports.net/profiles/4372'}\n",
      "Scraped player 40: {'Player Name': 'Roman Safiullin', 'Location': 'M • Russia', 'Singles UTR': '15.45', 'Doubles UTR': '14.61', 'Profile Link': 'https://app.utrsports.net/profiles/60156'}\n",
      "No more pages to scrape or 'Next' button not found.\n",
      "Data saved to player_statistics.csv.\n",
      "WebDriver closed.\n"
     ]
    }
   ],
   "source": [
    "# --- Complete Revised Script ---\n",
    "\n",
    "# Import necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Verify credentials are loaded\n",
    "if not email or not password:\n",
    "    raise ValueError(\"Email or password not found in environment variables.\")\n",
    "\n",
    "# Define the is_float function\n",
    "def is_float(value):\n",
    "    \"\"\"Check if the provided value can be converted to a float.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='scraper.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Start maximized for better visibility\n",
    "\n",
    "# Uncomment the next line to run Chrome in headless mode after successful debugging\n",
    "# chrome_options.add_argument(\"--headless\")  \n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Define WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "# Define the login URL and the player's stats URL\n",
    "login_url = \"https://app.utrsports.net/login\"\n",
    "stats_url = \"https://app.utrsports.net/search?sportTypes=tennis&startDate=11/21/2024&utrMin=1&utrMax=16&utrType=verified&utrTeamType=singles&utrFitPosition=6&type=players&lat=37.2358078&lng=-121.9623751\"\n",
    "\n",
    "def scrape_current_page(driver, wait, base_url):\n",
    "    \"\"\"Scrape player data from the current page.\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        # Locate all player cards\n",
    "        player_cards = driver.find_elements(By.CLASS_NAME, \"search__cardContainer__1Z9Ee\")  # Ensure this is the correct class\n",
    "        logging.info(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "        print(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "\n",
    "        for idx, card in enumerate(player_cards, start=1):\n",
    "            try:\n",
    "                # Extract player name within the current card\n",
    "                try:\n",
    "                    name_element = card.find_element(By.CSS_SELECTOR, \"div.name.show-ellipsis\")\n",
    "                    player_name = name_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    player_name = \"N/A\"\n",
    "                    logging.warning(f\"Player name not found for player {idx}: {e}\")\n",
    "                    print(f\"Player name not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract player location within the current card\n",
    "                try:\n",
    "                    location_element = card.find_element(By.CSS_SELECTOR, \"div.place.show-ellipsis\")\n",
    "                    location = location_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    location = \"N/A\"\n",
    "                    logging.warning(f\"Location not found for player {idx}: {e}\")\n",
    "                    print(f\"Location not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract UTR values within the current card\n",
    "                try:\n",
    "                    utr_elements = card.find_elements(By.XPATH, \".//div[@title='Rated']\")\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "\n",
    "                    if len(utr_elements) >= 2:\n",
    "                        # Extract Singles UTR\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]  # Assuming format \"16.25 Verified\"\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "\n",
    "                        # Extract Doubles UTR\n",
    "                        doubles_utr_text = utr_elements[1].text.strip()\n",
    "                        doubles_utr = doubles_utr_text.split()[0]  # Assuming format \"15.26 Verified\"\n",
    "                        if not is_float(doubles_utr):\n",
    "                            doubles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                            print(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                    elif len(utr_elements) == 1:\n",
    "                        # Only Singles UTR found\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No UTR values found for player {idx}.\")\n",
    "                        print(f\"No UTR values found for player {idx}.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "                    logging.warning(f\"UTR not found for player {idx}: {e}\")\n",
    "                    print(f\"UTR not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract Profile Link within the current card\n",
    "                try:\n",
    "                    profile_link_element = card.find_element(By.TAG_NAME, \"a\")\n",
    "                    relative_profile_link = profile_link_element.get_attribute(\"href\")\n",
    "                    # Ensure the link is absolute\n",
    "                    if relative_profile_link.startswith(\"/\"):\n",
    "                        profile_link = base_url + relative_profile_link\n",
    "                    else:\n",
    "                        profile_link = relative_profile_link\n",
    "                except Exception as e:\n",
    "                    profile_link = \"N/A\"\n",
    "                    logging.warning(f\"Profile link not found for player {idx}: {e}\")\n",
    "                    print(f\"Profile link not found for player {idx}: {e}\")\n",
    "\n",
    "                # Compile the data\n",
    "                player_data = {\n",
    "                    'Player Name': player_name,\n",
    "                    'Location': location,\n",
    "                    'Singles UTR': singles_utr,\n",
    "                    'Doubles UTR': doubles_utr,\n",
    "                    'Profile Link': profile_link\n",
    "                }\n",
    "\n",
    "                data.append(player_data)\n",
    "                logging.info(f\"Scraped player {idx}: {player_data}\")\n",
    "                print(f\"Scraped player {idx}: {player_data}\")\n",
    "\n",
    "            except Exception as card_e:\n",
    "                logging.error(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                driver.save_screenshot(f\"error_scraping_player_{idx}.png\")\n",
    "                print(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                continue  # Proceed to next card\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error locating player cards: {e}\")\n",
    "        driver.save_screenshot(\"error_locating_player_cards.png\")\n",
    "        print(f\"Error locating player cards: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_all_pages(driver, wait, base_url):\n",
    "    \"\"\"Scrape data from all paginated pages.\"\"\"\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        logging.info(f\"Scraping page {page}.\")\n",
    "        print(f\"Scraping page {page}.\")\n",
    "\n",
    "        # Scrape data from the current page\n",
    "        page_data = scrape_current_page(driver, wait, base_url)\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "        # Check if \"Next\" button is present and clickable\n",
    "        try:\n",
    "            next_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='Next']\"))  # Replace with actual XPath\n",
    "            )\n",
    "            next_button.click()\n",
    "            logging.info(\"Clicked the 'Next' button.\")\n",
    "            print(\"Clicked the 'Next' button.\")\n",
    "            page += 1\n",
    "            time.sleep(3)  # Wait for the next page to load\n",
    "        except Exception as e:\n",
    "            logging.info(\"No more pages to scrape or 'Next' button not found.\")\n",
    "            print(\"No more pages to scrape or 'Next' button not found.\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename='player_statistics.csv'):\n",
    "    \"\"\"Save the scraped data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Data saved to {filename}.\")\n",
    "        print(f\"Data saved to {filename}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving data to CSV: {e}\")\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the scraping workflow.\"\"\"\n",
    "    base_url = \"https://app.utrsports.net\"  # Define the base URL\n",
    "\n",
    "    try:\n",
    "        # Navigate to the login page\n",
    "        driver.get(login_url)\n",
    "        logging.info(\"Navigated to the login page.\")\n",
    "        print(\"Navigated to the login page.\")\n",
    "\n",
    "        # Allow the page to load completely\n",
    "        time.sleep(3)  # Adjust based on your internet speed\n",
    "\n",
    "        # Locate the email input field\n",
    "        try:\n",
    "            email_field = wait.until(EC.presence_of_element_located((By.ID, \"emailInput\")))  # Replace with actual ID\n",
    "            email_field.clear()\n",
    "            email_field.send_keys(email)\n",
    "            logging.info(\"Entered email.\")\n",
    "            print(\"Entered email.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Email input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_email_field.png\")\n",
    "            print(f\"Email input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate the password input field\n",
    "        try:\n",
    "            password_field = driver.find_element(By.ID, \"passwordInput\")  # Replace with actual ID\n",
    "            password_field.clear()\n",
    "            password_field.send_keys(password)\n",
    "            logging.info(\"Entered password.\")\n",
    "            print(\"Entered password.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Password input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_password_field.png\")\n",
    "            print(f\"Password input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate and click the login button\n",
    "        try:\n",
    "            sign_in_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='SIGN IN']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", sign_in_button)\n",
    "            sign_in_button.click()\n",
    "            logging.info(\"Clicked the 'SIGN IN' button.\")\n",
    "            print(\"Clicked the 'SIGN IN' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_sign_in.png\")\n",
    "            print(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Wait until the \"Continue\" button appears and click it\n",
    "        try:\n",
    "            continue_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='Continue']\"))\n",
    "            )\n",
    "            continue_button.click()\n",
    "            logging.info(\"Clicked the 'Continue' button.\")\n",
    "            print(\"Clicked the 'Continue' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_continue.png\")\n",
    "            print(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Navigate to the Player's Stats Page\n",
    "        try:\n",
    "            driver.get(stats_url)\n",
    "            logging.info(f\"Navigated to player's stats page: {stats_url}\")\n",
    "            print(f\"Navigated to player's stats page: {stats_url}\")\n",
    "\n",
    "            # Allow the stats page to load\n",
    "            time.sleep(5)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.save_screenshot(\"error_navigate_stats_page.png\")\n",
    "            print(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Scrape all pages (if paginated)\n",
    "        all_data = scrape_all_pages(driver, wait, base_url)\n",
    "\n",
    "        # Save the data to CSV\n",
    "        save_to_csv(all_data)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        logging.error(f\"An unexpected error occurred: {main_e}\")\n",
    "        driver.save_screenshot(\"unexpected_error.png\")\n",
    "        print(f\"An unexpected error occurred: {main_e}\")\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "        logging.info(\"WebDriver closed.\")\n",
    "        print(\"WebDriver closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Complete Revised Script ---\n",
    "\n",
    "# Import necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Verify credentials are loaded\n",
    "if not email or not password:\n",
    "    raise ValueError(\"Email or password not found in environment variables.\")\n",
    "\n",
    "# Define the is_float function\n",
    "def is_float(value):\n",
    "    \"\"\"Check if the provided value can be converted to a float.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='scraper.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Start maximized for better visibility\n",
    "\n",
    "# Uncomment the next line to run Chrome in headless mode after successful debugging\n",
    "# chrome_options.add_argument(\"--headless\")  \n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Define WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "# Define the login URL and the player's stats URL\n",
    "login_url = \"https://app.utrsports.net/login\"\n",
    "stats_url = \"https://app.utrsports.net/search?sportTypes=tennis&startDate=11/21/2024&utrMin=1&utrMax=16&utrType=verified&utrTeamType=singles&utrFitPosition=6&type=players&lat=37.2358078&lng=-121.9623751\"\n",
    "\n",
    "def click_load_more(driver, wait):\n",
    "    \"\"\"Click the 'Load More' button until it's no longer present.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Locate the 'Load More' button\n",
    "            load_more_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[span[text()='Load More']]\"))\n",
    "            )\n",
    "            # Scroll to the 'Load More' button to ensure it's in view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "            # Click the 'Load More' button\n",
    "            load_more_button.click()\n",
    "            logging.info(\"Clicked the 'Load More' button.\")\n",
    "            print(\"Clicked the 'Load More' button.\")\n",
    "            # Wait for new content to load\n",
    "            time.sleep(3)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.info(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            print(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            break\n",
    "\n",
    "def scrape_current_page(driver, wait, base_url):\n",
    "    \"\"\"Scrape player data from the current page.\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        # Locate all player cards\n",
    "        player_cards = driver.find_elements(By.CLASS_NAME, \"search__cardContainer__1Z9Ee\")  # Ensure this is the correct class\n",
    "        logging.info(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "        print(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "\n",
    "        for idx, card in enumerate(player_cards, start=1):\n",
    "            try:\n",
    "                # Extract player name within the current card\n",
    "                try:\n",
    "                    name_element = card.find_element(By.CSS_SELECTOR, \"div.name.show-ellipsis\")\n",
    "                    player_name = name_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    player_name = \"N/A\"\n",
    "                    logging.warning(f\"Player name not found for player {idx}: {e}\")\n",
    "                    print(f\"Player name not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract player location within the current card\n",
    "                try:\n",
    "                    location_element = card.find_element(By.CSS_SELECTOR, \"div.place.show-ellipsis\")\n",
    "                    location = location_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    location = \"N/A\"\n",
    "                    logging.warning(f\"Location not found for player {idx}: {e}\")\n",
    "                    print(f\"Location not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract UTR values within the current card\n",
    "                try:\n",
    "                    utr_elements = card.find_elements(By.XPATH, \".//div[@title='Rated']\")\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "\n",
    "                    if len(utr_elements) >= 2:\n",
    "                        # Extract Singles UTR\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]  # Assuming format \"16.25 Verified\"\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "\n",
    "                        # Extract Doubles UTR\n",
    "                        doubles_utr_text = utr_elements[1].text.strip()\n",
    "                        doubles_utr = doubles_utr_text.split()[0]  # Assuming format \"15.26 Verified\"\n",
    "                        if not is_float(doubles_utr):\n",
    "                            doubles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                            print(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                    elif len(utr_elements) == 1:\n",
    "                        # Only Singles UTR found\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No UTR values found for player {idx}.\")\n",
    "                        print(f\"No UTR values found for player {idx}.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "                    logging.warning(f\"UTR not found for player {idx}: {e}\")\n",
    "                    print(f\"UTR not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract Profile Link within the current card\n",
    "                try:\n",
    "                    profile_link_element = card.find_element(By.TAG_NAME, \"a\")\n",
    "                    relative_profile_link = profile_link_element.get_attribute(\"href\")\n",
    "                    # Ensure the link is absolute\n",
    "                    if relative_profile_link.startswith(\"/\"):\n",
    "                        profile_link = base_url + relative_profile_link\n",
    "                    else:\n",
    "                        profile_link = relative_profile_link\n",
    "                except Exception as e:\n",
    "                    profile_link = \"N/A\"\n",
    "                    logging.warning(f\"Profile link not found for player {idx}: {e}\")\n",
    "                    print(f\"Profile link not found for player {idx}: {e}\")\n",
    "\n",
    "                # Compile the data\n",
    "                player_data = {\n",
    "                    'Player Name': player_name,\n",
    "                    'Location': location,\n",
    "                    'Singles UTR': singles_utr,\n",
    "                    'Doubles UTR': doubles_utr,\n",
    "                    'Profile Link': profile_link\n",
    "                }\n",
    "\n",
    "                data.append(player_data)\n",
    "                logging.info(f\"Scraped player {idx}: {player_data}\")\n",
    "                print(f\"Scraped player {idx}: {player_data}\")\n",
    "\n",
    "            except Exception as card_e:\n",
    "                logging.error(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                driver.save_screenshot(f\"error_scraping_player_{idx}.png\")\n",
    "                print(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                continue  # Proceed to next card\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error locating player cards: {e}\")\n",
    "        driver.save_screenshot(\"error_locating_player_cards.png\")\n",
    "        print(f\"Error locating player cards: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_all_pages(driver, wait, base_url):\n",
    "    \"\"\"Scrape data from all paginated pages.\"\"\"\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        logging.info(f\"Scraping page {page}.\")\n",
    "        print(f\"Scraping page {page}.\")\n",
    "\n",
    "        # Scrape data from the current page\n",
    "        page_data = scrape_current_page(driver, wait, base_url)\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "        # Attempt to locate the \"Load More\" button\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "            page += 1\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename='player_statistics.csv'):\n",
    "    \"\"\"Save the scraped data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Data saved to {filename}.\")\n",
    "        print(f\"Data saved to {filename}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving data to CSV: {e}\")\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the scraping workflow.\"\"\"\n",
    "    base_url = \"https://app.utrsports.net\"  # Define the base URL\n",
    "\n",
    "    try:\n",
    "        # Navigate to the login page\n",
    "        driver.get(login_url)\n",
    "        logging.info(\"Navigated to the login page.\")\n",
    "        print(\"Navigated to the login page.\")\n",
    "\n",
    "        # Allow the page to load completely\n",
    "        time.sleep(3)  # Adjust based on your internet speed\n",
    "\n",
    "        # Locate the email input field\n",
    "        try:\n",
    "            email_field = wait.until(EC.presence_of_element_located((By.ID, \"emailInput\")))  # Replace with actual ID\n",
    "            email_field.clear()\n",
    "            email_field.send_keys(email)\n",
    "            logging.info(\"Entered email.\")\n",
    "            print(\"Entered email.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Email input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_email_field.png\")\n",
    "            print(f\"Email input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate the password input field\n",
    "        try:\n",
    "            password_field = driver.find_element(By.ID, \"passwordInput\")  # Replace with actual ID\n",
    "            password_field.clear()\n",
    "            password_field.send_keys(password)\n",
    "            logging.info(\"Entered password.\")\n",
    "            print(\"Entered password.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Password input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_password_field.png\")\n",
    "            print(f\"Password input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate and click the login button\n",
    "        try:\n",
    "            sign_in_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='SIGN IN']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", sign_in_button)\n",
    "            sign_in_button.click()\n",
    "            logging.info(\"Clicked the 'SIGN IN' button.\")\n",
    "            print(\"Clicked the 'SIGN IN' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_sign_in.png\")\n",
    "            print(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Wait until the \"Continue\" button appears and click it\n",
    "        try:\n",
    "            continue_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='Continue']\"))\n",
    "            )\n",
    "            continue_button.click()\n",
    "            logging.info(\"Clicked the 'Continue' button.\")\n",
    "            print(\"Clicked the 'Continue' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_continue.png\")\n",
    "            print(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Navigate to the Player's Stats Page\n",
    "        try:\n",
    "            driver.get(stats_url)\n",
    "            logging.info(f\"Navigated to player's stats page: {stats_url}\")\n",
    "            print(f\"Navigated to player's stats page: {stats_url}\")\n",
    "\n",
    "            # Allow the stats page to load\n",
    "            time.sleep(5)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.save_screenshot(\"error_navigate_stats_page.png\")\n",
    "            print(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Click the \"Load More\" button until all data is loaded\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "\n",
    "        # Scrape all pages (now all data is loaded)\n",
    "        all_data = scrape_current_page(driver, wait, base_url)\n",
    "\n",
    "        # Save the data to CSV\n",
    "        save_to_csv(all_data)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        logging.error(f\"An unexpected error occurred: {main_e}\")\n",
    "        driver.save_screenshot(\"unexpected_error.png\")\n",
    "        print(f\"An unexpected error occurred: {main_e}\")\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "        logging.info(\"WebDriver closed.\")\n",
    "        print(\"WebDriver closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Complete Revised Script with Filter Interaction ---\n",
    "\n",
    "# Import necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Verify credentials are loaded\n",
    "if not email or not password:\n",
    "    raise ValueError(\"Email or password not found in environment variables.\")\n",
    "\n",
    "# Define the is_float function\n",
    "def is_float(value):\n",
    "    \"\"\"Check if the provided value can be converted to a float.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='scraper.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Start maximized for better visibility\n",
    "\n",
    "# Uncomment the next line to run Chrome in headless mode after successful debugging\n",
    "# chrome_options.add_argument(\"--headless\")  \n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Define WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "# Define the login URL and the player's stats URL\n",
    "login_url = \"https://app.utrsports.net/login\"\n",
    "stats_url = \"https://app.utrsports.net/search?sportTypes=tennis&startDate=11/21/2024&utrMin=1&utrMax=16&utrType=verified&utrTeamType=singles&utrFitPosition=6&type=players&lat=37.2358078&lng=-121.9623751\"\n",
    "\n",
    "def apply_filter(driver, wait, filter_name, option):\n",
    "    \"\"\"\n",
    "    Applies a filter on the UTR Sports website.\n",
    "\n",
    "    :param driver: Selenium WebDriver instance.\n",
    "    :param wait: WebDriverWait instance.\n",
    "    :param filter_name: The name of the filter to apply (e.g., 'Gender').\n",
    "    :param option: The option to select within the filter (e.g., 'Male').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate the filter button by its visible text\n",
    "        filter_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//button[contains(text(), '{filter_name}')]\")\n",
    "            )\n",
    "        )\n",
    "        filter_button.click()\n",
    "        logging.info(f\"Clicked the '{filter_name}' filter button.\")\n",
    "        print(f\"Clicked the '{filter_name}' filter button.\")\n",
    "\n",
    "        # Wait for the filter options to appear\n",
    "        # Using a more precise XPath to locate the option button directly\n",
    "        option_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//button[text()='{option}']\")\n",
    "            )\n",
    "        )\n",
    "        option_button.click()\n",
    "        logging.info(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "        print(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "\n",
    "        # Optional: Wait for the page to refresh/update after applying the filter\n",
    "        time.sleep(3)  # Adjust based on your internet speed and website response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to apply filter '{filter_name}' with option '{option}': {e}\")\n",
    "        print(f\"Failed to apply filter '{filter_name}' with option '{option}': {e}\")\n",
    "        driver.save_screenshot(f\"error_apply_filter_{filter_name}_{option}.png\")\n",
    "\n",
    "\n",
    "def click_load_more(driver, wait):\n",
    "    \"\"\"Click the 'Load More' button until it's no longer present.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Locate the 'Load More' button\n",
    "            load_more_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[span[text()='Load More']]\"))\n",
    "            )\n",
    "            # Scroll to the 'Load More' button to ensure it's in view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "            # Click the 'Load More' button\n",
    "            load_more_button.click()\n",
    "            logging.info(\"Clicked the 'Load More' button.\")\n",
    "            print(\"Clicked the 'Load More' button.\")\n",
    "            # Wait for new content to load\n",
    "            time.sleep(3)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.info(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            print(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            break\n",
    "\n",
    "def scrape_current_page(driver, wait, base_url):\n",
    "    \"\"\"Scrape player data from the current page.\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        # Locate all player cards\n",
    "        player_cards = driver.find_elements(By.CLASS_NAME, \"search__cardContainer__1Z9Ee\")  # Ensure this is the correct class\n",
    "        logging.info(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "        print(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "\n",
    "        for idx, card in enumerate(player_cards, start=1):\n",
    "            try:\n",
    "                # Extract player name within the current card\n",
    "                try:\n",
    "                    name_element = card.find_element(By.CSS_SELECTOR, \"div.name.show-ellipsis\")\n",
    "                    player_name = name_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    player_name = \"N/A\"\n",
    "                    logging.warning(f\"Player name not found for player {idx}: {e}\")\n",
    "                    print(f\"Player name not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract player location within the current card\n",
    "                try:\n",
    "                    location_element = card.find_element(By.CSS_SELECTOR, \"div.place.show-ellipsis\")\n",
    "                    location = location_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    location = \"N/A\"\n",
    "                    logging.warning(f\"Location not found for player {idx}: {e}\")\n",
    "                    print(f\"Location not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract UTR values within the current card\n",
    "                try:\n",
    "                    utr_elements = card.find_elements(By.XPATH, \".//div[@title='Rated']\")\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "\n",
    "                    if len(utr_elements) >= 2:\n",
    "                        # Extract Singles UTR\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]  # Assuming format \"16.25 Verified\"\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "\n",
    "                        # Extract Doubles UTR\n",
    "                        doubles_utr_text = utr_elements[1].text.strip()\n",
    "                        doubles_utr = doubles_utr_text.split()[0]  # Assuming format \"15.26 Verified\"\n",
    "                        if not is_float(doubles_utr):\n",
    "                            doubles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                            print(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                    elif len(utr_elements) == 1:\n",
    "                        # Only Singles UTR found\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No UTR values found for player {idx}.\")\n",
    "                        print(f\"No UTR values found for player {idx}.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "                    logging.warning(f\"UTR not found for player {idx}: {e}\")\n",
    "                    print(f\"UTR not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract Profile Link within the current card\n",
    "                try:\n",
    "                    profile_link_element = card.find_element(By.TAG_NAME, \"a\")\n",
    "                    relative_profile_link = profile_link_element.get_attribute(\"href\")\n",
    "                    # Ensure the link is absolute\n",
    "                    if relative_profile_link.startswith(\"/\"):\n",
    "                        profile_link = base_url + relative_profile_link\n",
    "                    else:\n",
    "                        profile_link = relative_profile_link\n",
    "                except Exception as e:\n",
    "                    profile_link = \"N/A\"\n",
    "                    logging.warning(f\"Profile link not found for player {idx}: {e}\")\n",
    "                    print(f\"Profile link not found for player {idx}: {e}\")\n",
    "\n",
    "                # Compile the data\n",
    "                player_data = {\n",
    "                    'Player Name': player_name,\n",
    "                    'Location': location,\n",
    "                    'Singles UTR': singles_utr,\n",
    "                    'Doubles UTR': doubles_utr,\n",
    "                    'Profile Link': profile_link\n",
    "                }\n",
    "\n",
    "                data.append(player_data)\n",
    "                logging.info(f\"Scraped player {idx}: {player_data}\")\n",
    "                print(f\"Scraped player {idx}: {player_data}\")\n",
    "\n",
    "            except Exception as card_e:\n",
    "                logging.error(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                driver.save_screenshot(f\"error_scraping_player_{idx}.png\")\n",
    "                print(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                continue  # Proceed to next card\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error locating player cards: {e}\")\n",
    "        driver.save_screenshot(\"error_locating_player_cards.png\")\n",
    "        print(f\"Error locating player cards: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_all_pages(driver, wait, base_url):\n",
    "    \"\"\"Scrape data from all paginated pages.\"\"\"\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        logging.info(f\"Scraping page {page}.\")\n",
    "        print(f\"Scraping page {page}.\")\n",
    "\n",
    "        # Scrape data from the current page\n",
    "        page_data = scrape_current_page(driver, wait, base_url)\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "        # Attempt to locate the \"Load More\" button\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "            page += 1\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename='player_statistics.csv'):\n",
    "    \"\"\"Save the scraped data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Data saved to {filename}.\")\n",
    "        print(f\"Data saved to {filename}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving data to CSV: {e}\")\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the scraping workflow.\"\"\"\n",
    "    base_url = \"https://app.utrsports.net\"  # Define the base URL\n",
    "\n",
    "    try:\n",
    "        # Navigate to the login page\n",
    "        driver.get(login_url)\n",
    "        logging.info(\"Navigated to the login page.\")\n",
    "        print(\"Navigated to the login page.\")\n",
    "\n",
    "        # Allow the page to load completely\n",
    "        time.sleep(3)  # Adjust based on your internet speed\n",
    "\n",
    "        # Locate the email input field\n",
    "        try:\n",
    "            email_field = wait.until(EC.presence_of_element_located((By.ID, \"emailInput\")))  # Replace with actual ID\n",
    "            email_field.clear()\n",
    "            email_field.send_keys(email)\n",
    "            logging.info(\"Entered email.\")\n",
    "            print(\"Entered email.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Email input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_email_field.png\")\n",
    "            print(f\"Email input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate the password input field\n",
    "        try:\n",
    "            password_field = driver.find_element(By.ID, \"passwordInput\")  # Replace with actual ID\n",
    "            password_field.clear()\n",
    "            password_field.send_keys(password)\n",
    "            logging.info(\"Entered password.\")\n",
    "            print(\"Entered password.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Password input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_password_field.png\")\n",
    "            print(f\"Password input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate and click the login button\n",
    "        try:\n",
    "            sign_in_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='SIGN IN']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", sign_in_button)\n",
    "            sign_in_button.click()\n",
    "            logging.info(\"Clicked the 'SIGN IN' button.\")\n",
    "            print(\"Clicked the 'SIGN IN' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_sign_in.png\")\n",
    "            print(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Wait until the \"Continue\" button appears and click it\n",
    "        try:\n",
    "            continue_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='Continue']\"))\n",
    "            )\n",
    "            continue_button.click()\n",
    "            logging.info(\"Clicked the 'Continue' button.\")\n",
    "            print(\"Clicked the 'Continue' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_continue.png\")\n",
    "            print(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Navigate to the Player's Stats Page\n",
    "        try:\n",
    "            driver.get(stats_url)\n",
    "            logging.info(f\"Navigated to player's stats page: {stats_url}\")\n",
    "            print(f\"Navigated to player's stats page: {stats_url}\")\n",
    "\n",
    "            # Allow the stats page to load\n",
    "            time.sleep(5)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.save_screenshot(\"error_navigate_stats_page.png\")\n",
    "            print(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Apply Filters (e.g., Gender: Male)\n",
    "        try:\n",
    "            apply_filter(driver, wait, filter_name=\"Gender\", option=\"Male\")\n",
    "            # Add more filters as needed by calling apply_filter with different parameters\n",
    "            # Example:\n",
    "            # apply_filter(driver, wait, filter_name=\"Age\", option=\"18-25\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error applying filters: {e}\")\n",
    "            driver.save_screenshot(\"error_apply_filters.png\")\n",
    "            print(f\"Error applying filters: {e}\")\n",
    "\n",
    "        # Click the \"Load More\" button until all data is loaded\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "\n",
    "        # Scrape all pages (now all data is loaded)\n",
    "        all_data = scrape_current_page(driver, wait, base_url)\n",
    "\n",
    "        # Save the data to CSV\n",
    "        save_to_csv(all_data)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        logging.error(f\"An unexpected error occurred: {main_e}\")\n",
    "        driver.save_screenshot(\"unexpected_error.png\")\n",
    "        print(f\"An unexpected error occurred: {main_e}\")\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "        logging.info(\"WebDriver closed.\")\n",
    "        print(\"WebDriver closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding radio button filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Complete Revised Script with \"Gender\" and \"Segment\" Filters ---\n",
    "\n",
    "# Import necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve credentials\n",
    "email = os.getenv('UTR_EMAIL')\n",
    "password = os.getenv('UTR_PASSWORD')\n",
    "\n",
    "# Verify credentials are loaded\n",
    "if not email or not password:\n",
    "    raise ValueError(\"Email or password not found in environment variables.\")\n",
    "\n",
    "# Define the is_float function\n",
    "def is_float(value):\n",
    "    \"\"\"Check if the provided value can be converted to a float.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='scraper.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
    ")\n",
    "\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--start-maximized\")  # Start maximized for better visibility\n",
    "\n",
    "# Uncomment the next line to run Chrome in headless mode after successful debugging\n",
    "# chrome_options.add_argument(\"--headless\")  \n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# Define WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "# Define the login URL and the player's stats URL\n",
    "login_url = \"https://app.utrsports.net/login\"\n",
    "stats_url = \"https://app.utrsports.net/search?sportTypes=tennis&startDate=11/21/2024&utrMin=1&utrMax=16&utrType=verified&utrTeamType=singles&utrFitPosition=6&type=players&lat=37.2358078&lng=-121.9623751\"\n",
    "\n",
    "def apply_filter(driver, wait, filter_name, option):\n",
    "    \"\"\"\n",
    "    Applies a button-based filter on the UTR Sports website.\n",
    "\n",
    "    :param driver: Selenium WebDriver instance.\n",
    "    :param wait: WebDriverWait instance.\n",
    "    :param filter_name: The name of the filter to apply (e.g., 'Gender').\n",
    "    :param option: The option to select within the filter (e.g., 'Male').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate the filter button by its visible text\n",
    "        filter_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//button[contains(text(), '{filter_name}')]\")\n",
    "            )\n",
    "        )\n",
    "        filter_button.click()\n",
    "        logging.info(f\"Clicked the '{filter_name}' filter button.\")\n",
    "        print(f\"Clicked the '{filter_name}' filter button.\")\n",
    "\n",
    "        # Wait for the filter options to appear\n",
    "        # Assuming options are displayed as buttons within the filter dropdown/modal\n",
    "        option_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//button[text()='{option}']\")\n",
    "            )\n",
    "        )\n",
    "        option_button.click()\n",
    "        logging.info(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "        print(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "\n",
    "        # Optional: Wait for the page to refresh/update after applying the filter\n",
    "        time.sleep(3)  # Adjust based on your internet speed and website response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to apply filter '{filter_name}' with option '{option}': {e}\")\n",
    "        print(f\"Failed to apply filter '{filter_name}' with option '{option}': {e}\")\n",
    "        driver.save_screenshot(f\"error_apply_filter_{filter_name}_{option}.png\")\n",
    "\n",
    "def apply_radio_filter(driver, wait, filter_name, option):\n",
    "    \"\"\"\n",
    "    Applies a radio button filter on the UTR Sports website.\n",
    "\n",
    "    :param driver: Selenium WebDriver instance.\n",
    "    :param wait: WebDriverWait instance.\n",
    "    :param filter_name: The name of the filter to apply (e.g., 'Segment').\n",
    "    :param option: The radio button option to select within the filter (e.g., 'Pro').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Locate the filter button by its visible text\n",
    "        filter_button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//button[contains(text(), '{filter_name}')]\")\n",
    "            )\n",
    "        )\n",
    "        filter_button.click()\n",
    "        logging.info(f\"Clicked the '{filter_name}' filter button.\")\n",
    "        print(f\"Clicked the '{filter_name}' filter button.\")\n",
    "\n",
    "        # Wait for the filter modal or dropdown to appear\n",
    "        wait.until(\n",
    "            EC.visibility_of_element_located(\n",
    "                (By.CLASS_NAME, \"search__searchFilterModalBody__1EtSh\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Locate the radio button option by its label text\n",
    "        option_label = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, f\"//label[contains(text(), '{option}')]\")\n",
    "            )\n",
    "        )\n",
    "        option_label.click()\n",
    "        logging.info(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "        print(f\"Selected '{option}' from '{filter_name}' filter.\")\n",
    "\n",
    "        # Optional: Wait for the page to refresh/update after applying the filter\n",
    "        time.sleep(3)  # Adjust based on your internet speed and website response\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to apply radio filter '{filter_name}' with option '{option}': {e}\")\n",
    "        print(f\"Failed to apply radio filter '{filter_name}' with option '{option}': {e}\")\n",
    "        driver.save_screenshot(f\"error_apply_radio_filter_{filter_name}_{option}.png\")\n",
    "\n",
    "def click_load_more(driver, wait):\n",
    "    \"\"\"Click the 'Load More' button until it's no longer present.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Locate the 'Load More' button\n",
    "            load_more_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[span[text()='Load More']]\"))\n",
    "            )\n",
    "            # Scroll to the 'Load More' button to ensure it's in view\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", load_more_button)\n",
    "            # Click the 'Load More' button\n",
    "            load_more_button.click()\n",
    "            logging.info(\"Clicked the 'Load More' button.\")\n",
    "            print(\"Clicked the 'Load More' button.\")\n",
    "            # Wait for new content to load\n",
    "            time.sleep(3)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.info(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            print(\"No more 'Load More' buttons to click or button not found.\")\n",
    "            break\n",
    "\n",
    "def scrape_current_page(driver, wait, base_url):\n",
    "    \"\"\"Scrape player data from the current page.\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        # Locate all player cards\n",
    "        player_cards = driver.find_elements(By.CLASS_NAME, \"search__cardContainer__1Z9Ee\")  # Ensure this is the correct class\n",
    "        logging.info(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "        print(f\"Found {len(player_cards)} player cards on the current page.\")\n",
    "\n",
    "        for idx, card in enumerate(player_cards, start=1):\n",
    "            try:\n",
    "                # Extract player name within the current card\n",
    "                try:\n",
    "                    name_element = card.find_element(By.CSS_SELECTOR, \"div.name.show-ellipsis\")\n",
    "                    player_name = name_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    player_name = \"N/A\"\n",
    "                    logging.warning(f\"Player name not found for player {idx}: {e}\")\n",
    "                    print(f\"Player name not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract player location within the current card\n",
    "                try:\n",
    "                    location_element = card.find_element(By.CSS_SELECTOR, \"div.place.show-ellipsis\")\n",
    "                    location = location_element.text.strip()\n",
    "                except Exception as e:\n",
    "                    location = \"N/A\"\n",
    "                    logging.warning(f\"Location not found for player {idx}: {e}\")\n",
    "                    print(f\"Location not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract UTR values within the current card\n",
    "                try:\n",
    "                    utr_elements = card.find_elements(By.XPATH, \".//div[@title='Rated']\")\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "\n",
    "                    if len(utr_elements) >= 2:\n",
    "                        # Extract Singles UTR\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]  # Assuming format \"16.25 Verified\"\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "\n",
    "                        # Extract Doubles UTR\n",
    "                        doubles_utr_text = utr_elements[1].text.strip()\n",
    "                        doubles_utr = doubles_utr_text.split()[0]  # Assuming format \"15.26 Verified\"\n",
    "                        if not is_float(doubles_utr):\n",
    "                            doubles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                            print(f\"Invalid Doubles UTR value for player {idx}: {doubles_utr_text}\")\n",
    "                    elif len(utr_elements) == 1:\n",
    "                        # Only Singles UTR found\n",
    "                        singles_utr_text = utr_elements[0].text.strip()\n",
    "                        singles_utr = singles_utr_text.split()[0]\n",
    "                        if not is_float(singles_utr):\n",
    "                            singles_utr = \"N/A\"\n",
    "                            logging.warning(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                            print(f\"Invalid Singles UTR value for player {idx}: {singles_utr_text}\")\n",
    "                    else:\n",
    "                        logging.warning(f\"No UTR values found for player {idx}.\")\n",
    "                        print(f\"No UTR values found for player {idx}.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    singles_utr = \"N/A\"\n",
    "                    doubles_utr = \"N/A\"\n",
    "                    logging.warning(f\"UTR not found for player {idx}: {e}\")\n",
    "                    print(f\"UTR not found for player {idx}: {e}\")\n",
    "\n",
    "                # Extract Profile Link within the current card\n",
    "                try:\n",
    "                    profile_link_element = card.find_element(By.TAG_NAME, \"a\")\n",
    "                    relative_profile_link = profile_link_element.get_attribute(\"href\")\n",
    "                    # Ensure the link is absolute\n",
    "                    if relative_profile_link.startswith(\"/\"):\n",
    "                        profile_link = base_url + relative_profile_link\n",
    "                    else:\n",
    "                        profile_link = relative_profile_link\n",
    "                except Exception as e:\n",
    "                    profile_link = \"N/A\"\n",
    "                    logging.warning(f\"Profile link not found for player {idx}: {e}\")\n",
    "                    print(f\"Profile link not found for player {idx}: {e}\")\n",
    "\n",
    "                # Compile the data\n",
    "                player_data = {\n",
    "                    'Player Name': player_name,\n",
    "                    'Location': location,\n",
    "                    'Singles UTR': singles_utr,\n",
    "                    'Doubles UTR': doubles_utr,\n",
    "                    'Profile Link': profile_link\n",
    "                }\n",
    "\n",
    "                data.append(player_data)\n",
    "                logging.info(f\"Scraped player {idx}: {player_data}\")\n",
    "                print(f\"Scraped player {idx}: {player_data}\")\n",
    "\n",
    "            except Exception as card_e:\n",
    "                logging.error(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                driver.save_screenshot(f\"error_scraping_player_{idx}.png\")\n",
    "                print(f\"Error scraping player card {idx}: {card_e}\")\n",
    "                continue  # Proceed to next card\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error locating player cards: {e}\")\n",
    "        driver.save_screenshot(\"error_locating_player_cards.png\")\n",
    "        print(f\"Error locating player cards: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def scrape_all_pages(driver, wait, base_url):\n",
    "    \"\"\"Scrape data from all paginated pages.\"\"\"\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        logging.info(f\"Scraping page {page}.\")\n",
    "        print(f\"Scraping page {page}.\")\n",
    "\n",
    "        # Scrape data from the current page\n",
    "        page_data = scrape_current_page(driver, wait, base_url)\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "        # Attempt to locate the \"Load More\" button\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "            page += 1\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def save_to_csv(data, filename='player_statistics.csv'):\n",
    "    \"\"\"Save the scraped data to a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False)\n",
    "        logging.info(f\"Data saved to {filename}.\")\n",
    "        print(f\"Data saved to {filename}.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving data to CSV: {e}\")\n",
    "        print(f\"Error saving data to CSV: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the scraping workflow.\"\"\"\n",
    "    base_url = \"https://app.utrsports.net\"  # Define the base URL\n",
    "\n",
    "    try:\n",
    "        # Navigate to the login page\n",
    "        driver.get(login_url)\n",
    "        logging.info(\"Navigated to the login page.\")\n",
    "        print(\"Navigated to the login page.\")\n",
    "\n",
    "        # Allow the page to load completely\n",
    "        time.sleep(3)  # Adjust based on your internet speed\n",
    "\n",
    "        # Locate the email input field\n",
    "        try:\n",
    "            email_field = wait.until(EC.presence_of_element_located((By.ID, \"emailInput\")))  # Replace with actual ID\n",
    "            email_field.clear()\n",
    "            email_field.send_keys(email)\n",
    "            logging.info(\"Entered email.\")\n",
    "            print(\"Entered email.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Email input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_email_field.png\")\n",
    "            print(f\"Email input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate the password input field\n",
    "        try:\n",
    "            password_field = driver.find_element(By.ID, \"passwordInput\")  # Replace with actual ID\n",
    "            password_field.clear()\n",
    "            password_field.send_keys(password)\n",
    "            logging.info(\"Entered password.\")\n",
    "            print(\"Entered password.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Password input field not found: {e}\")\n",
    "            driver.save_screenshot(\"error_password_field.png\")\n",
    "            print(f\"Password input field not found: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Locate and click the login button\n",
    "        try:\n",
    "            sign_in_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='SIGN IN']\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", sign_in_button)\n",
    "            sign_in_button.click()\n",
    "            logging.info(\"Clicked the 'SIGN IN' button.\")\n",
    "            print(\"Clicked the 'SIGN IN' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_sign_in.png\")\n",
    "            print(f\"An error occurred while clicking the 'SIGN IN' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Wait until the \"Continue\" button appears and click it\n",
    "        try:\n",
    "            continue_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[text()='Continue']\"))\n",
    "            )\n",
    "            continue_button.click()\n",
    "            logging.info(\"Clicked the 'Continue' button.\")\n",
    "            print(\"Clicked the 'Continue' button.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.save_screenshot(\"error_click_continue.png\")\n",
    "            print(f\"An error occurred while clicking the 'Continue' button: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Navigate to the Player's Stats Page\n",
    "        try:\n",
    "            driver.get(stats_url)\n",
    "            logging.info(f\"Navigated to player's stats page: {stats_url}\")\n",
    "            print(f\"Navigated to player's stats page: {stats_url}\")\n",
    "\n",
    "            # Allow the stats page to load\n",
    "            time.sleep(5)  # Adjust based on your internet speed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.save_screenshot(\"error_navigate_stats_page.png\")\n",
    "            print(f\"Error navigating to player's stats page: {e}\")\n",
    "            driver.quit()\n",
    "            return\n",
    "\n",
    "        # Apply Filters\n",
    "\n",
    "        # 1. Apply Gender Filter (Existing Functionality)\n",
    "        try:\n",
    "            apply_filter(driver, wait, filter_name=\"Gender\", option=\"Male\")\n",
    "            # Add more button-based filters as needed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error applying 'Gender' filter: {e}\")\n",
    "            driver.save_screenshot(\"error_apply_gender_filter.png\")\n",
    "            print(f\"Error applying 'Gender' filter: {e}\")\n",
    "\n",
    "        # 2. Apply Segment Filter (New Functionality)\n",
    "        try:\n",
    "            apply_radio_filter(driver, wait, filter_name=\"Segment\", option=\"Pro\")\n",
    "            # You can change 'Pro' to any other segment like 'College', 'High School', etc.\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error applying 'Segment' filter: {e}\")\n",
    "            driver.save_screenshot(\"error_apply_segment_filter.png\")\n",
    "            print(f\"Error applying 'Segment' filter: {e}\")\n",
    "\n",
    "        # Click the \"Load More\" button until all data is loaded\n",
    "        try:\n",
    "            click_load_more(driver, wait)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while clicking 'Load More': {e}\")\n",
    "            driver.save_screenshot(\"error_load_more.png\")\n",
    "            print(f\"Error while clicking 'Load More': {e}\")\n",
    "\n",
    "        # Scrape all pages (now all data is loaded)\n",
    "        all_data = scrape_current_page(driver, wait, base_url)\n",
    "\n",
    "        # Save the data to CSV\n",
    "        save_to_csv(all_data)\n",
    "\n",
    "    except Exception as main_e:\n",
    "        logging.error(f\"An unexpected error occurred: {main_e}\")\n",
    "        driver.save_screenshot(\"unexpected_error.png\")\n",
    "        print(f\"An unexpected error occurred: {main_e}\")\n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "        logging.info(\"WebDriver closed.\")\n",
    "        print(\"WebDriver closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
